{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: COMP 671D, Machine Learning\n",
    "# Homework Assignment 2 \n",
    "# Problem 3\n",
    "# Name: Samuel Eure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/euresa/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(10)\n",
    "def showMessage(dropped):\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"Feature importances having dropped \"+dropped)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"Feature \\t : Importance\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ProPublica_COMPAS_preprocessed.csv\")\n",
    "data = np.array(df.iloc[:,1:])\n",
    "features = df.columns.tolist()[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into $4/5$ training data and $1/5$ testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(data[:,:-1], \n",
    "                                                   data[:,-1], \n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and fitting the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation. Below, my test accuracy and F1 score should be printed out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.6431064572425829\n",
      "     F1 Score : 0.2792321116928446\n"
     ]
    }
   ],
   "source": [
    "def getValues(clf, x_test, y_test):\n",
    "    predictions = clf.predict(x_test)\n",
    "\n",
    "    tp = sum(predictions*y_test)\n",
    "    tn = sum((predictions-1)*(y_test-1))\n",
    "    n  = len(y_test)\n",
    "    fp = abs(sum(predictions*(y_test-1)))\n",
    "    fn = abs(sum((predictions-1)*y_test))\n",
    "\n",
    "    accuracy  = (tp+tn)/n\n",
    "    precision = tp/(tp+fn)\n",
    "    recall    = tp/(tn+fp)\n",
    "    f1        = 2*(precision*recall/(precision+recall))\n",
    "\n",
    "    print(\"Test Accuracy :\", accuracy)\n",
    "    print(\"     F1 Score :\", f1)\n",
    "getValues(clf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, I will print out the relative importances of each of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature : Importance\n",
      "p_current_age: \t 0.2754\n",
      "p_age_first_offense: \t 0.252\n",
      "p_charge: \t 0.2842\n",
      "p_jail30: \t 0.0122\n",
      "p_prison: \t 0.0369\n",
      "p_probation: \t 0.0772\n",
      "race_black: \t 0.0257\n",
      "race_white: \t 0.0194\n",
      "race_hispanic: \t 0.0123\n",
      "race_asian: \t 0.0025\n",
      "race_native: \t 0.0023\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature : Importance\" )\n",
    "importance = clf.feature_importances_\n",
    "for i in range(len(features)):\n",
    "    print(features[i]+\": \\t \"+str(np.round(importance[i],4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From what is shown above, it appears that given the age, first offense, and charge of a person, their race makes little difference. That is, the relative importance of these three variables (which convey the information of age and part of the criminal history) outways that of race by roughly a factor of 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the top two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will first remove $\\textbf{charge}$ and $\\textbf{current_age}$ from the data set since they have the highest feature importances. Then, I will retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From This Model:\n",
      "Test Accuracy : 0.6300174520069808\n",
      "     F1 Score : 0.23385689354275743\n",
      "---------------------------------------------------------------\n",
      "Feature importances having dropped CHARGE and CURRENT_AGE\n",
      "---------------------------------------------------------------\n",
      "Feature \t : Importance\n",
      "p_age_first_offense: \t 0.6052\n",
      "p_jail30: \t 0.0328\n",
      "p_prison: \t 0.1001\n",
      "p_probation: \t 0.1745\n",
      "race_black: \t 0.048\n",
      "race_white: \t 0.0182\n",
      "race_hispanic: \t 0.013\n",
      "race_asian: \t 0.0051\n",
      "race_native: \t 0.0033\n"
     ]
    }
   ],
   "source": [
    "twoDf = df.drop(['p_charge', 'p_current_age'], axis = 1)\n",
    "dataTrim = np.array(twoDf.iloc[:,1:])\n",
    "features = twoDf.columns.tolist()[1:-1]\n",
    "x_train2,x_test2, y_train2, y_test2 = train_test_split(dataTrim[:,:-1],\n",
    "                                                   dataTrim[:,-1], \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train2, y_train2)\n",
    "print(\"From This Model:\")\n",
    "getValues(clf, x_test2, y_test2)\n",
    "showMessage(\"CHARGE and CURRENT_AGE\")\n",
    "importance = clf.feature_importances_\n",
    "for i in range(len(features)):\n",
    "    print(features[i]+\": \\t \"+str(np.round(importance[i],4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It appears that the importance of race may have increased compared to what it was prior to the removal of $\\textbf{charge}$ and $\\textbf{current_age}$, however all the contributions of race are still small compared to factors such as $\\textbf{prison, probation}$ and $\\textbf{age_first_offense}$. Thus, this model doesn't place race as a primary factor into the classification of recidivism either. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing only one feature. First, I'll train the model by only removing $\\textbf{charge}$, and then I'll train a model by only removing $\\textbf{current_age}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.6413612565445026\n",
      "     F1 Score : 0.3019197207678883\n",
      "---------------------------------------------------------------\n",
      "Feature importances having dropped CHARGE\n",
      "---------------------------------------------------------------\n",
      "Feature \t : Importance\n",
      "p_current_age: \t 0.3852\n",
      "p_age_first_offense: \t 0.3689\n",
      "p_jail30: \t 0.0145\n",
      "p_prison: \t 0.0569\n",
      "p_probation: \t 0.1163\n",
      "race_black: \t 0.0218\n",
      "race_white: \t 0.0177\n",
      "race_hispanic: \t 0.0123\n",
      "race_asian: \t 0.0044\n",
      "race_native: \t 0.002\n"
     ]
    }
   ],
   "source": [
    "oneDf1 = df.drop(['p_charge'], axis = 1)\n",
    "dataTrim = np.array(oneDf1.iloc[:,1:])\n",
    "features = oneDf1.columns.tolist()[1:-1]\n",
    "x_train11,x_test11, y_train11, y_test11 = train_test_split(dataTrim[:,:-1],\n",
    "                                                   dataTrim[:,-1], \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train11, y_train11)\n",
    "getValues(clf, x_test11, y_test11)\n",
    "showMessage(\"CHARGE\")\n",
    "importance = clf.feature_importances_\n",
    "for i in range(len(features)):\n",
    "    print(features[i]+\": \\t \"+str(np.round(importance[i],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.5881326352530541\n",
      "     F1 Score : 0.2530541012216405\n",
      "---------------------------------------------------------------\n",
      "Feature importances having dropped CURRENT_AGE\n",
      "---------------------------------------------------------------\n",
      "Feature \t : Importance\n",
      "p_age_first_offense: \t 0.4398\n",
      "p_charge: \t 0.3516\n",
      "p_jail30: \t 0.0138\n",
      "p_prison: \t 0.0493\n",
      "p_probation: \t 0.0914\n",
      "race_black: \t 0.0215\n",
      "race_white: \t 0.0161\n",
      "race_hispanic: \t 0.0113\n",
      "race_asian: \t 0.0025\n",
      "race_native: \t 0.0027\n"
     ]
    }
   ],
   "source": [
    "oneDf2 = df.drop(['p_current_age'], axis = 1)\n",
    "dataTrim = np.array(oneDf2.iloc[:,1:])\n",
    "features = oneDf2.columns.tolist()[1:-1]\n",
    "x_train12,x_test12, y_train12, y_test12 = train_test_split(dataTrim[:,:-1],\n",
    "                                                   dataTrim[:,-1], \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train12, y_train12)\n",
    "getValues(clf, x_test12, y_test12)\n",
    "showMessage(\"CURRENT_AGE\")\n",
    "importance = clf.feature_importances_\n",
    "for i in range(len(features)):\n",
    "    print(features[i]+\": \\t \"+str(np.round(importance[i],4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It appears that when removing only of of the original top two features, the importance of race does still not change and become one of the primary predictors of recidivism. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this part of the problem, I will use Logistic Regression as my linear model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6675392670157068\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(x_train, y_train)\n",
    "coef = model.coef_[0]\n",
    "print(\"Accuracy: \",str(model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :\t coefficient\n",
      "p_age_first_offense: \t -0.0217\n",
      "p_charge: \t -0.022\n",
      "p_jail30: \t 0.0491\n",
      "p_prison: \t -0.2327\n",
      "p_probation: \t -0.0237\n",
      "race_black: \t 0.0517\n",
      "race_white: \t 0.2042\n",
      "race_hispanic: \t 0.0454\n",
      "race_asian: \t -0.1538\n",
      "race_native: \t -0.8843\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature :\\t coefficient\" )\n",
    "for i in range(len(features)):\n",
    "    print(features[i]+\": \\t \"+str(np.round(coef[i],4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above, I print the coefficients for each of the features used in the logistic regression. Since the scale of $\\textbf{race_white, race_native}$ and $\\textbf{race_asian}$ would suggest these are some of the strongest predictors of recidivism, these findings are not consistent with the results of the Random Forest Classifier. For example, predictor most heavily weighted is $\\textbf{race_native}$. I'll also note that the accuracy of this model is slightly better than that of Random Forest classifier (however only the default settings of the Random Forest classifier was used, while logistic regressions doesn't really have tuning parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don't believe the answer to this question is as black and white as the question itself - no pun indented. After a short literature review of this issue, it appears that ProPublica's main claim is that when they predicted the performance of the COMPAS model using logistic regression, they ended up having race as a statistically significant predictor of recidivism and that race was used in a \"biased\" way in order to classify criminals. Moreover, although they seem to have performed the Logistic Regression is a correct way, the model they are evaluating is still only around 60% accurate on average anyway. As for my results after running the logistic regression, I obtained similar qualitative results (i.e. I found race to be a significant predictor of recidivism for the logistic regression), however when I fitted the data to a Random Forest model, I obtained similar accuracies and this model didn't determine race to be a main predictor in recidivism rates. It seems that the two methods may be valid and similarly accurate ways of predicting recidivism, however they do so by evaluating the factors in different ways. Furthermore, the accuracy of predictions of recidivism rates for white and black criminals is roughly the same, however the error attributed to black criminals typically arrose by overpredicting the risk of recidivism while the opposite was true for whites. \n",
    "\n",
    "#### I would argue that thet specific statistical test they implimented used race as a statistically significant predictor in classification, however had they used a differ classification model, they may have come to a different conclusion. Moreover, I believe they're focusing the errors of the models as being primarily due to race (they mention that they still find race to be a primary classification factor even after conditioning on other factors) when they should be focusing on the overall validity of the model in the first place. The COMPAS model still only correct about 60 percent of the time, so the face that there are error with it's use of classification (errors that may envolve the use of race) shouldn't be surprising in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
