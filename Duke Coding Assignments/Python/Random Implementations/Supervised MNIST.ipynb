{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) =  mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting some data to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "plt.figure()\n",
    "plt.imshow(x_train[i])\n",
    "plt.grid(False)\n",
    "plt.title(str(y_train[i]), size = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the training data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We're going to use a Neural Network because this \n",
    "   is dataset of images, and Neural Networks are great \n",
    "   for working with image data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_1.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.2888 - accuracy: 0.9218\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_1.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can get a more accurate model by increaseing the capacity of the model by increasing the number of layers.\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_2.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 13s 6ms/step - loss: 0.4744 - accuracy: 0.8572\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3325 - accuracy: 0.9053\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3237 - accuracy: 0.9074\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3104 - accuracy: 0.9136\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3020 - accuracy: 0.9149\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2972 - accuracy: 0.9166\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2804 - accuracy: 0.9206 0s - loss: 0.2803 - accuracy: \n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2854 - accuracy: 0.9200\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.2849 - accuracy: 0.9198\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2753 - accuracy: 0.9216\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.2730 - accuracy: 0.9219\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2742 - accuracy: 0.9218\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2756 - accuracy: 0.9228\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2707 - accuracy: 0.9233\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2615 - accuracy: 0.9274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe38fd88160>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 5s - loss: 0.2584 - accuracy: 0.9254\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_2.evaluate(x_train, y_train, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.2930 - accuracy: 0.9201\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_2.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fe38fd61048>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = []\n",
    "some_list.append(tf.keras.layers.Dense(10))\n",
    "some_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(number_of_layers, nodes, number_of_epochs, x, y):\n",
    "    \n",
    "    layers = []\n",
    "    layers.append(tf.keras.layers.Flatten(input_shape = (28,28)))\n",
    "    \n",
    "    for i in range(number_of_layers):\n",
    "        layers.append(tf.keras.layers.Dense(nodes[i],activation = 'relu'))\n",
    "   \n",
    "    layers.append(tf.keras.layers.Dense(10))\n",
    "    \n",
    "    model = tf.keras.Sequential(layers)\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics = ['accuracy'])\n",
    "    model.fit(x, y, epochs = number_of_epochs)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(number_of_layers, nodes, number_of_epochs, x, y):\n",
    "    \n",
    "    layers = []\n",
    "    layers.append(tf.keras.layers.Flatten(input_shape = (28,28)))\n",
    "    \n",
    "    for i in range(number_of_layers):\n",
    "        layers.append(tf.keras.layers.Dense(nodes[i],activation = 'relu'))\n",
    "   \n",
    "    layers.append(tf.keras.layers.Dense(10))\n",
    "    \n",
    "    model = tf.keras.Sequential(layers)\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics = ['accuracy'])\n",
    "    model.fit(x, y, epochs = number_of_epochs)\n",
    "    return(model)\n",
    "\n",
    "def get_training_acc(model):\n",
    "    loss, acc = model.evaluate(x_train, y_train, verbose = 2)\n",
    "    return(acc)\n",
    "\n",
    "def get_testing_acc(model):\n",
    "    loss, acc = model.evaluate(x_test, y_test, verbose = 2)\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.87 - 15s 7ms/step - loss: 0.4352 - accuracy: 0.8757\n",
      "1875/1875 - 8s - loss: 0.1279 - accuracy: 0.9634\n",
      "313/313 - 1s - loss: 0.1339 - accuracy: 0.9616\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 22s 10ms/step - loss: 0.4230 - accuracy: 0.8806\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1147 - accuracy: 0.9664\n",
      "1875/1875 - 5s - loss: 0.0819 - accuracy: 0.9755\n",
      "313/313 - 1s - loss: 0.0999 - accuracy: 0.9677\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.4294 - accuracy: 0.8774\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1218 - accuracy: 0.9645\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0758 - accuracy: 0.9772\n",
      "1875/1875 - 7s - loss: 0.0506 - accuracy: 0.9858\n",
      "313/313 - 3s - loss: 0.0769 - accuracy: 0.9761\n",
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.4359 - accuracy: 0.8749\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1258 - accuracy: 0.9625\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0801 - accuracy: 0.9763\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0553 - accuracy: 0.9842\n",
      "1875/1875 - 6s - loss: 0.0488 - accuracy: 0.9851\n",
      "313/313 - 2s - loss: 0.0837 - accuracy: 0.9755\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 13s 6ms/step - loss: 0.4345 - accuracy: 0.8768\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1192 - accuracy: 0.9659\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0761 - accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0584 - accuracy: 0.9821\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0423 - accuracy: 0.9871\n",
      "1875/1875 - 5s - loss: 0.0310 - accuracy: 0.9910\n",
      "313/313 - 2s - loss: 0.0743 - accuracy: 0.9776\n",
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4369 - accuracy: 0.8780: 0s - loss: 0.4512 - ac\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1169 - accuracy: 0.9664\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0779 - accuracy: 0.9762\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0567 - accuracy: 0.9833\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0431 - accuracy: 0.9864\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9894\n",
      "1875/1875 - 5s - loss: 0.0249 - accuracy: 0.9926\n",
      "313/313 - 1s - loss: 0.0821 - accuracy: 0.9773\n",
      "Epoch 1/7\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4396 - accuracy: 0.8745\n",
      "Epoch 2/7\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1230 - accuracy: 0.9634\n",
      "Epoch 3/7\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0790 - accuracy: 0.9774\n",
      "Epoch 4/7\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0613 - accuracy: 0.9814\n",
      "Epoch 5/7\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0445 - accuracy: 0.9863\n",
      "Epoch 6/7\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0349 - accuracy: 0.9893: 0s - loss: 0.034\n",
      "Epoch 7/7\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0287 - accuracy: 0.9911\n",
      "1875/1875 - 4s - loss: 0.0178 - accuracy: 0.9954\n",
      "313/313 - 1s - loss: 0.0790 - accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "EPOCHS = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "for e in EPOCHS:\n",
    "    model = make_model(number_of_layers = 1, #I'll try training my model over different epochs\n",
    "                       nodes = [128], \n",
    "                       number_of_epochs = e, \n",
    "                       x = x_train, \n",
    "                       y = y_train)\n",
    "    train_acc.append(get_training_acc(model))\n",
    "    test_acc.append(get_testing_acc(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe2f415d0b8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(EPOCHS, 1- np.array(train_acc), c = 'blue', label = 'training error')\n",
    "plt.scatter(EPOCHS, 1-  np.array(test_acc), c = 'red', label = 'test error')\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate vs. Epochs\")\n",
    "plt.axhline(0, c = 'black')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
